{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec with gensim",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8ttdHFbaJngxj3+G9rmmE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GGpark1/Deep_Learning_Study/blob/master/Word2Vec_with_gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFA4na9irmHV",
        "outputId": "5b90a5e8-4c92-4d2d-d473-233516094ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2\n"
          ]
        }
      ],
      "source": [
        "#gensim 패키지 import\n",
        "\n",
        "!pip install gensim --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "gensim.__version__\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egO9MiN6ry6g",
        "outputId": "9f487e19-0e86-49a9-ddf8-8e8167f4a3a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gensim에 학습된 단어 확인\n",
        "\n",
        "for idx, word in enumerate(wv.index_to_key):\n",
        "    if idx == 10:\n",
        "        break\n",
        "\n",
        "    print(f\"word #{idx}/{len(wv.index_to_key)} is '{word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqXkyUdgr1e-",
        "outputId": "bf917935-b4bd-4e66-a0e9-9481e404307b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word #0/3000000 is '</s>'\n",
            "word #1/3000000 is 'in'\n",
            "word #2/3000000 is 'for'\n",
            "word #3/3000000 is 'that'\n",
            "word #4/3000000 is 'is'\n",
            "word #5/3000000 is 'on'\n",
            "word #6/3000000 is '##'\n",
            "word #7/3000000 is 'The'\n",
            "word #8/3000000 is 'with'\n",
            "word #9/3000000 is 'said'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#벡터화된 단어 확인\n",
        "\n",
        "vec_king = wv['king']\n",
        "\n",
        "print(f\"임베딩 벡터의 차원 수 : {vec_king.shape}\\n\")\n",
        "print(f\"'king'의 임베딩 벡터 \\n\\n {vec_king}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S82deZh2u493",
        "outputId": "9561b9c5-8bf5-4116-f4e2-1694bf793f43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 벡터의 차원 수 : (300,)\n",
            "\n",
            "'king'의 임베딩 벡터 \n",
            "\n",
            " [ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
            " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
            "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
            " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
            "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
            "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
            "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
            "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
            "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
            "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
            "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
            "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
            " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
            " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
            " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
            "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
            "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
            " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
            " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
            " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
            "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
            "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
            "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
            " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
            " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
            "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
            " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
            "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
            " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
            " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
            "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
            " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
            " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
            "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
            " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
            "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
            "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
            " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
            " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
            " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
            " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
            " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
            "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
            "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
            "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
            " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
            "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
            "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
            " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
            " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
            " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
            "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
            "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
            " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
            "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
            " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
            "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
            "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
            " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
            "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
            "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
            "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
            "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
            "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
            " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
            "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
            " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
            "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
            "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
            " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
            "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
            "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
            "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
            " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
            " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#oov 확인\n",
        "\n",
        "unk = 'cameroon'\n",
        "\n",
        "try:\n",
        "    vec_unk = wv[unk]\n",
        "except KeyError:\n",
        "    print(f\"\"\"단어 \"{unk}\"은 해당 모델에는 등장하지 않는 단어입니다.\"\"\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtwGoEouvOOu",
        "outputId": "5f4c0838-6be5-448d-db13-0c997f097ed2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 \"cameroon\"은 해당 모델에는 등장하지 않는 단어입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "         ('car', 'minivan'),\n",
        "         ('car', 'bicycle'),\n",
        "         ('car', 'airplane'),\n",
        "         ('car', 'cereal'),\n",
        "         ('car', 'democracy')]\n",
        "\n",
        "for w1, w2 in pairs:\n",
        "    print(f'{w1} ==== {w2}\\t {wv.similarity(w1, w2):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu3LCVwmvpVf",
        "outputId": "74dcae61-b171-48a5-9020-33f6811133b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car ==== minivan\t 0.69\n",
            "car ==== bicycle\t 0.54\n",
            "car ==== airplane\t 0.42\n",
            "car ==== cereal\t 0.14\n",
            "car ==== democracy\t 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (word, similarity) in enumerate(wv.most_similar(positive=['car', 'minivan'], topn=6)):\n",
        "    print(f\"Top {i+1} : {word}, {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLcIn4j7wSxM",
        "outputId": "0153efd6-4d8b-468d-c15a-331b6a3fc5df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 : SUV, 0.8532192707061768\n",
            "Top 2 : vehicle, 0.8175783753395081\n",
            "Top 3 : pickup_truck, 0.7763688564300537\n",
            "Top 4 : Jeep, 0.7567334175109863\n",
            "Top 5 : Ford_Explorer, 0.7565720081329346\n",
            "Top 6 : sedan, 0.7446292042732239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#king 벡터에 women 벡터를 더한 뒤(positive) men 벡터를 빼주는(negative) 과정\n",
        "#walking 벡터에 swam 벡터를 더한 뒤 walked 벡터를 빼주는 과정\n",
        "\n",
        "print(wv.most_similar(positive=['king', 'women'], negative=['men'], topn=1))\n",
        "print(wv.most_similar(positive=['walking', 'swam'], negative=['walked'], topn=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q2WSCVHw3-d",
        "outputId": "5912598b-d27c-4b1a-a44c-35ff5be2e911"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.6525818109512329)]\n",
            "[('swimming', 0.7448815703392029)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 list 중에서 가장 관계 없는 단어 뽑아보기\n",
        "\n",
        "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAV5k2tDx2tA",
        "outputId": "dd1b4094-09db-4fb7-fdd7-edc900631ec7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "metadata": {
        "id": "07eoIy94yFUM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#임베딩 벡터를 사용하여 문장 분류하기\n",
        "#seed 고정\n",
        "#데이터셋 split\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6Ko7m605j6E",
        "outputId": "26c322b0-8a38-4e01-948e-38779345b25d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "17473536/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train set shape : {X_train.shape}\")\n",
        "print(f\"Test set shape : {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04jBlFYP6Yz6",
        "outputId": "9c0bba15-e8f3-4d2c-b31e-d1b544ec61d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape : (25000,)\n",
            "Test set shape : (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#index를 text로 변환하고 문장으로 만드는 함수\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i) for i in text])"
      ],
      "metadata": {
        "id": "LuJKCdxtB85T"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_review(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "zj0L0BQpFMV2",
        "outputId": "f66fb2ef-96d3-43c2-c9ba-ac4dc54a4ab2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텍스트 학습\n",
        "\n",
        "sentences = [decode_review(idx) for idx in X_train]\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "metadata": {
        "id": "xOr-Am0sFd8P"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#임베딩 매트릭스를 만들기 위한 단어 집합 크기 계산\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihBcjz9dGBix",
        "outputId": "0bdf6cef-3a38-41c9-a5e3-7ba8fd6220e4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19999"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text를 벡터화\n",
        "\n",
        "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "X_encoded"
      ],
      "metadata": {
        "id": "GndACbH1GDQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'학습 데이터에 있는 문서의 평균 토큰 수: {np.mean([len(sent) for sent in X_encoded], dtype=int)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqb-wLjWLYHW",
        "outputId": "eff286b8-fd76-4bed-ac20-37a74dceb533"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터에 있는 문서의 평균 토큰 수: 238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#벡터를 패딩처리\n",
        "\n",
        "maxlen_pad = 400 \n",
        "\n",
        "X_train=pad_sequences(X_encoded, maxlen=maxlen_pad, padding = 'post')\n",
        "y_train=np.array(y_train)"
      ],
      "metadata": {
        "id": "BUb9F1mgMAQf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#임베딩 가중치 행렬 만들기\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "def get_vector(word):\n",
        "    if word in wv:\n",
        "        return wv[word]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    temp = get_vector(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp"
      ],
      "metadata": {
        "id": "BFbMBlKgMVRN"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DrWvCOPMWpD",
        "outputId": "78c103f8-7cc2-4b10-aebb-4736e2cb7a2e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 0.09082031, -0.21777344, -0.07226562, ...,  0.32226562,\n",
              "        -0.05957031, -0.11328125],\n",
              "       [-0.265625  ,  0.25585938, -0.01855469, ...,  0.0480957 ,\n",
              "         0.34765625,  0.01177979],\n",
              "       [-0.05541992,  0.26367188,  0.18457031, ..., -0.16503906,\n",
              "        -0.25976562, -0.14257812]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten"
      ],
      "metadata": {
        "id": "vvhAC8egRR_r"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 구축\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 300, weights = [embedding_matrix], input_length = maxlen_pad, trainable=False))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "XBAW6B2bRTtg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YQmQ9xGRw_d",
        "outputId": "cee1f654-1800-4d2e-aaba-e16106b7651b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 13s 37ms/step - loss: 0.6924 - acc: 0.5268 - val_loss: 0.6907 - val_acc: 0.5996\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6901 - acc: 0.5767 - val_loss: 0.6882 - val_acc: 0.5972\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6880 - acc: 0.5899 - val_loss: 0.6859 - val_acc: 0.6006\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6861 - acc: 0.5918 - val_loss: 0.6837 - val_acc: 0.5928\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 0.6845 - acc: 0.5949 - val_loss: 0.6824 - val_acc: 0.5970\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6827 - acc: 0.5957 - val_loss: 0.6800 - val_acc: 0.5946\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6813 - acc: 0.6028 - val_loss: 0.6787 - val_acc: 0.6112\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6798 - acc: 0.6058 - val_loss: 0.6774 - val_acc: 0.6092\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6784 - acc: 0.6048 - val_loss: 0.6755 - val_acc: 0.6150\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6772 - acc: 0.6078 - val_loss: 0.6742 - val_acc: 0.6168\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6759 - acc: 0.6100 - val_loss: 0.6730 - val_acc: 0.6172\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6748 - acc: 0.6116 - val_loss: 0.6716 - val_acc: 0.6192\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6736 - acc: 0.6095 - val_loss: 0.6712 - val_acc: 0.6128\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6725 - acc: 0.6135 - val_loss: 0.6690 - val_acc: 0.6246\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6712 - acc: 0.6158 - val_loss: 0.6679 - val_acc: 0.6212\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6704 - acc: 0.6147 - val_loss: 0.6673 - val_acc: 0.6222\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6693 - acc: 0.6191 - val_loss: 0.6670 - val_acc: 0.6196\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6684 - acc: 0.6217 - val_loss: 0.6649 - val_acc: 0.6268\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6674 - acc: 0.6205 - val_loss: 0.6641 - val_acc: 0.6266\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6666 - acc: 0.6248 - val_loss: 0.6633 - val_acc: 0.6274\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcbe8956350>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [decode_review(idx) for idx in X_test]\n",
        "\n",
        "X_test_encoded = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "X_test=pad_sequences(X_test_encoded, maxlen=400, padding='post')\n",
        "y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "8I0V-76JSCMZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFGAZcq2SJmK",
        "outputId": "6ec2b7f3-a115-4a46-fc7a-e837fedae9ed"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6680 - acc: 0.6093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6679654121398926, 0.609279990196228]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}